{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Zero Latency Raw Bridge From Windows Camera to Linux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download and Install FFMPEG\n",
    "\n",
    "```powershell\n",
    "New-Item -ItemType Directory -Force -Path \"C:\\Tools\"\n",
    "Set-Location \"C:\\Tools\"\n",
    "Invoke-WebRequest -Uri \"https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip\" -OutFile \"ffmpeg.zip\"\n",
    "Expand-Archive -Path \"ffmpeg.zip\" -DestinationPath \"C:\\Tools\\ffmpeg\" -Force\n",
    "Set-Location \"C:\\Tools\"\n",
    "Invoke-WebRequest -Uri \"https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip\" -OutFile \"ffmpeg.zip\"\n",
    "Expand-Archive -Path \"ffmpeg.zip\" -DestinationPath \"C:\\Tools\\ffmpeg\" -Force\n",
    "```\n",
    "\n",
    "#### Find the path\n",
    "\n",
    "```powershell\n",
    "PS C:\\Tools> Get-ChildItem \"C:\\Tools\\ffmpeg\" -Recurse -Filter ffmpeg.exe | Select-Object -First 1 FullName\n",
    "```\n",
    "\n",
    "#### output FullName\n",
    "    C:\\Tools\\ffmpeg\\ffmpeg-8.0-essentials_build\\bin\\ffmpeg.exe\n",
    "    \n",
    "#### Test Path\n",
    "\n",
    "```powershell\n",
    "PS C:\\Tools> & \"C:\\Tools\\ffmpeg\\ffmpeg-8.0-essentials_build\\bin\\ffmpeg.exe\" -version\n",
    "```\n",
    "\n",
    "#### Set Environment Variable and List Devices\n",
    "\n",
    "```powershell\n",
    "PS C:\\Tools> $env:FFMPEG=\"C:\\Tools\\ffmpeg\\ffmpeg-8.0-essentials_build\\bin\\ffmpeg.exe\" # Set FFMPEG environment variable\n",
    "PS C:\\Tools> & $env:FFMPEG -list_devices true -f dshow -i dummy # List devicesa\n",
    "```\n",
    "\n",
    "#### List Supported Formats for Camera\n",
    "\n",
    "```powershell\n",
    "& $env:FFMPEG -f dshow -list_options true -i video=\"USB Camera Name\" # see supported formats\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Python packages\n",
    "\n",
    "ultralytics, onnxruntime, onnx, opencv-python, numpy, Pillow, tqdm, simple-lama-inpainting, sympy, matplotlib, seaborn, pandas, ipywidgets .venv/bin/python -c \"from ultralytics import YOLO; YOLO('yolov8n-seg.pt')\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receive the Stream in WSL\n",
    "\n",
    "**Correct sequence:**\n",
    "\n",
    "1. Run the WSL server cell **first** â€”it will print \"Waiting for Windows connection (timeout in 30 seconds)...\"\n",
    "2. Within 30 seconds, run the ffmpeg command on Windows:\n",
    "\n",
    "```\n",
    "& \"C:\\Tools\\ffmpeg\\ffmpeg-8.0-essentials_build\\bin\\ffmpeg.exe\" ^\n",
    "  -f dshow ^\n",
    "  -rtbufsize 256M ^\n",
    "  -video_size 1280x720 ^\n",
    "  -framerate 30 ^\n",
    "  -i video=\"USB Camera\" ^\n",
    "  -pix_fmt bgr24 ^\n",
    "  -fflags nobuffer ^\n",
    "  -flags low_delay ^\n",
    "  -loglevel warning ^\n",
    "  -f rawvideo ^\n",
    "  \"tcp://172.24.146.232:5000\"\n",
    "```\n",
    "# Behavior:\n",
    " -  Starts listening on port 5000\n",
    " -  Waits 30 seconds for a connection from Windows ffmpeg\n",
    " -  During this wait, the cell is \"blocked\" - it doesn't proceed until either: \n",
    " -- Windows connects (success)\n",
    " -- 30 seconds timeout (failure)\n",
    "\n",
    "What happens during wait: Nothing - it's just listening for incoming TCP connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Windows connection (timeout in 30 seconds)...\n",
      "Connected to ('172.24.144.1', 49548)\n",
      "Frame 0: YOLO detected 1 people\n",
      "Frame 0: YOLO detected 1 people\n",
      "Frame 1: YOLO detected 1 people\n",
      "Frame 1: YOLO detected 1 people\n",
      "Frame 2: YOLO detected 1 people\n",
      "Frame 3: YOLO detected 1 people\n",
      "Frame 2: YOLO detected 1 people\n",
      "Frame 3: YOLO detected 1 people\n",
      "Frame 4: YOLO detected 1 people\n",
      "Frame 5: YOLO detected 1 people\n",
      "Frame 4: YOLO detected 1 people\n",
      "Frame 5: YOLO detected 1 people\n",
      "Frame 6: YOLO detected 1 people\n",
      "Frame 7: YOLO detected 1 people\n",
      "Frame 6: YOLO detected 1 people\n",
      "Frame 7: YOLO detected 1 people\n",
      "Frame 8: YOLO detected 1 people\n",
      "Frame 9: YOLO detected 1 people\n",
      "Frame 8: YOLO detected 1 people\n",
      "Frame 9: YOLO detected 1 people\n",
      "Processed 10 frames... FPS: 2.63\n",
      "Frame 10: YOLO detected 1 people\n",
      "Frame 11: YOLO detected 1 people\n",
      "Processed 10 frames... FPS: 2.63\n",
      "Frame 10: YOLO detected 1 people\n",
      "Frame 11: YOLO detected 1 people\n",
      "Frame 12: YOLO detected 1 people\n",
      "Frame 13: YOLO detected 1 people\n",
      "Frame 12: YOLO detected 1 people\n",
      "Frame 13: YOLO detected 1 people\n",
      "Frame 14: YOLO detected 1 people\n",
      "Frame 15: YOLO detected 1 people\n",
      "Frame 14: YOLO detected 1 people\n",
      "Frame 15: YOLO detected 1 people\n",
      "Frame 16: YOLO detected 1 people\n",
      "Frame 17: YOLO detected 1 people\n",
      "Frame 16: YOLO detected 1 people\n",
      "Frame 17: YOLO detected 1 people\n",
      "Frame 18: YOLO detected 1 people\n",
      "Frame 19: YOLO detected 1 people\n",
      "Frame 18: YOLO detected 1 people\n",
      "Frame 19: YOLO detected 1 people\n",
      "Processed 20 frames... FPS: 3.76\n",
      "Frame 20: YOLO detected 1 people\n",
      "Frame 21: YOLO detected 1 people\n",
      "Processed 20 frames... FPS: 3.76\n",
      "Frame 20: YOLO detected 1 people\n",
      "Frame 21: YOLO detected 1 people\n",
      "Frame 22: YOLO detected 1 people\n",
      "Frame 23: YOLO detected 1 people\n",
      "Frame 22: YOLO detected 1 people\n",
      "Frame 23: YOLO detected 1 people\n",
      "Frame 24: YOLO detected 1 people\n",
      "Frame 25: YOLO detected 1 people\n",
      "Frame 24: YOLO detected 1 people\n",
      "Frame 25: YOLO detected 1 people\n",
      "Frame 26: YOLO detected 1 people\n",
      "Frame 27: YOLO detected 1 people\n",
      "Frame 26: YOLO detected 1 people\n",
      "Frame 27: YOLO detected 1 people\n",
      "Frame 28: YOLO detected 1 people\n",
      "Frame 29: YOLO detected 1 people\n",
      "Frame 28: YOLO detected 1 people\n",
      "Frame 29: YOLO detected 1 people\n",
      "Processed 30 frames... FPS: 4.35\n",
      "Processing complete! Processed 30 frames.\n",
      "Videos not saved (save_videos=False)\n",
      "Processed 30 frames... FPS: 4.35\n",
      "Processing complete! Processed 30 frames.\n",
      "Videos not saved (save_videos=False)\n"
     ]
    }
   ],
   "source": [
    "# listen_raw_server.py with integrated processing\n",
    "import socket, numpy as np, cv2\n",
    "from ultralytics import YOLO\n",
    "from simple_lama_inpainting import SimpleLama\n",
    "import time\n",
    "import select\n",
    "\n",
    "HOST, PORT = \"0.0.0.0\", 5000\n",
    "\n",
    "W,H = 1280,720 # Set resolution here Must Match Client\n",
    "BYTES = W*H*3\n",
    "\n",
    "# Initialize frame counter\n",
    "frame_count = 0\n",
    "max_frames = 30  # Process 30 frames\n",
    "\n",
    "# Options\n",
    "save_videos = False  # Set to True to save videos, False for live-only\n",
    "\n",
    "# Load YOLO model\n",
    "yolo_model = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "# LaMa model\n",
    "lama_model = SimpleLama()\n",
    "\n",
    "# Initialize video writers if saving\n",
    "if save_videos:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out_original = cv2.VideoWriter('./Original_Webcam.avi', fourcc, 30, (W, H))\n",
    "    out_inpainted = cv2.VideoWriter('./SegYolov8_InptSimLama.avi', fourcc, 30, (W, H))\n",
    "\n",
    "# Create server socket\n",
    "srv = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "srv.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "srv.bind((HOST, PORT))\n",
    "srv.listen(1)\n",
    "\n",
    "print(\"Waiting for Windows connection (timeout in 30 seconds)...\")\n",
    "\n",
    "ready = select.select([srv], [], [], 30)\n",
    "\n",
    "if ready[0]:\n",
    "    conn, addr = srv.accept()\n",
    "    print(f\"Connected to {addr}\")\n",
    "    \n",
    "    buf = bytearray(BYTES)\n",
    "    mv = memoryview(buf)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while frame_count < max_frames:\n",
    "        got = 0\n",
    "        while got < BYTES:\n",
    "            n = conn.recv_into(mv[got:], BYTES - got)\n",
    "            if n == 0:\n",
    "                print(\"Connection closed by client\")\n",
    "                break\n",
    "            got += n\n",
    "        if got < BYTES:\n",
    "            break\n",
    "       # Convert buffer to image \n",
    "        frame = np.frombuffer(buf, np.uint8).reshape((H, W, 3)) # BGR format\n",
    "        \n",
    "        if save_videos:\n",
    "            # Write original frame\n",
    "            out_original.write(frame)\n",
    "        \n",
    "        # YOLO inference for people (class 0)\n",
    "        results = yolo_model(frame, classes=[0], verbose=False)\n",
    "        \n",
    "        print(f\"Frame {frame_count}: YOLO detected {len(results[0].masks) if results[0].masks is not None else 0} people\")\n",
    "        \n",
    "        # Create mask\n",
    "        if results[0].masks is not None and len(results[0].masks) > 0:\n",
    "            mask = results[0].masks.data[0].cpu().numpy()\n",
    "            mask = (mask * 255).astype(np.uint8)\n",
    "            mask = cv2.resize(mask, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "        else:\n",
    "            # No people, skip or use empty mask\n",
    "            mask = np.zeros((H, W), dtype=np.uint8)\n",
    "        \n",
    "        # Inpaint using LaMa\n",
    "        inpainted_result = lama_model(frame, mask)\n",
    "        if isinstance(inpainted_result, np.ndarray):\n",
    "            inpainted_frame = inpainted_result\n",
    "        else:\n",
    "            inpainted_frame = np.array(inpainted_result)\n",
    "            if len(inpainted_frame.shape) == 3 and inpainted_frame.shape[2] == 3:\n",
    "                inpainted_frame = cv2.cvtColor(inpainted_frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if save_videos:\n",
    "            # Write inpainted frame\n",
    "            out_inpainted.write(inpainted_frame)\n",
    "        \n",
    "        # Display real-time side-by-side feed\n",
    "        combined_frame = np.concatenate((frame, inpainted_frame), axis=1)\n",
    "        cv2.imshow('Real-time Side-by-Side Feed', combined_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"User pressed 'q' to quit real-time display\")\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        elapsed = time.time() - start_time\n",
    "        fps = frame_count / elapsed if elapsed > 0 else 0\n",
    "        if frame_count % 10 == 0:\n",
    "            print(f\"Processed {frame_count} frames... FPS: {fps:.2f}\")\n",
    "    \n",
    "    conn.close()\n",
    "else:\n",
    "    print(\"Timeout: No connection from Windows\")\n",
    "\n",
    "srv.close()\n",
    "if save_videos:\n",
    "    out_original.release()\n",
    "    out_inpainted.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processing complete! Processed {frame_count} frames.\")\n",
    "if save_videos:\n",
    "    print(\"Videos saved: ./Original_Webcam.avi and ./SegYolov8_InptSimLama.avi\")\n",
    "else:\n",
    "    print(\"Videos not saved (save_videos=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video processing with socket capture from raw server stream...\n",
      "Failed to capture frame 0 from socket\n",
      "Processing complete! Processed 0 frames from raw server stream.\n",
      "Videos saved: ./Original_Webcam.avi and ./SegYolov8_InptSimLama.avi\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from simple_lama_inpainting import SimpleLama\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import socket\n",
    "\n",
    "# Load YOLO model\n",
    "yolo_model = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "# LaMa model (uncomment if available)\n",
    "lama_model = SimpleLama()\n",
    "\n",
    "# Dummy inpainting function\n",
    "def dummy_inpainting(frame, mask):\n",
    "    # Simple dummy: just return the original frame\n",
    "    return frame\n",
    "\n",
    "# Capture a single frame from the raw TCP stream\n",
    "def capture_frame_from_socket():\n",
    "    \"\"\"Capture a single frame from the raw TCP stream on port 5000\"\"\"\n",
    "    s = socket.socket()\n",
    "    try:\n",
    "        s.connect((\"localhost\", 5000))\n",
    "    except ConnectionRefusedError:\n",
    "        return None\n",
    "    W, H = 1280, 720\n",
    "    BYTES = W * H * 3\n",
    "    buf = bytearray(BYTES)\n",
    "    mv = memoryview(buf)\n",
    "    got = 0\n",
    "    while got < BYTES:\n",
    "        n = s.recv_into(mv[got:], BYTES - got)\n",
    "        if n == 0:\n",
    "            s.close()\n",
    "            return None\n",
    "        got += n\n",
    "    frame = np.frombuffer(buf, np.uint8).reshape((H, W, 3))\n",
    "    s.close()\n",
    "    return frame\n",
    "\n",
    "# Camera properties (corrected for 720p)\n",
    "frame_width = 1280\n",
    "frame_height = 720\n",
    "fps = 30.0\n",
    "\n",
    "# Initialize video writers\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out_original = cv2.VideoWriter('./Original_Webcam.avi', fourcc, fps, (frame_width, frame_height))\n",
    "out_inpainted = cv2.VideoWriter('./SegYolov8_InptSimLama.avi', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "print(\"Starting video processing with socket capture from raw server stream...\")\n",
    "\n",
    "frame_count = 0\n",
    "max_frames = 30  # Capture 30 frames\n",
    "\n",
    "while frame_count < max_frames:\n",
    "    # Capture frame from socket\n",
    "    frame = capture_frame_from_socket()\n",
    "    \n",
    "    if frame is None:\n",
    "        print(f\"Failed to capture frame {frame_count} from socket\")\n",
    "        break\n",
    "    \n",
    "    # Write original frame\n",
    "    out_original.write(frame)\n",
    "\n",
    "    # YOLO inference for people (class 0)\n",
    "    results = yolo_model(frame, classes=[0], verbose=False)\n",
    "\n",
    "    print(f\"Frame {frame_count}: YOLO detected {len(results[0].masks) if results[0].masks is not None else 0} people\")\n",
    "\n",
    "    # For testing LaMa, create a synthetic mask if no people detected\n",
    "    if results[0].masks is not None and len(results[0].masks) > 0:\n",
    "        mask = results[0].masks.data[0].cpu().numpy()\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "        mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        print(f\"Using real mask with shape: {mask.shape}\")\n",
    "    else:\n",
    "        # Create synthetic circular mask for testing LaMa\n",
    "        mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
    "        center = (frame.shape[1] // 2, frame.shape[0] // 2)\n",
    "        radius = min(frame.shape[0], frame.shape[1]) // 4\n",
    "        cv2.circle(mask, center, radius, 255, -1)\n",
    "        print(f\"Using synthetic mask with shape: {mask.shape}\")\n",
    "\n",
    "    # Inpaint using LaMa\n",
    "    inpainted_result = lama_model(frame, mask)\n",
    "    print(f\"LaMa result type: {type(inpainted_result)}, shape: {getattr(inpainted_result, 'shape', 'no shape')}\")\n",
    "    # Convert PIL Image to numpy array for OpenCV\n",
    "    if isinstance(inpainted_result, np.ndarray):\n",
    "        inpainted_frame = inpainted_result\n",
    "    else:\n",
    "        # Convert PIL Image to numpy array (BGR format for OpenCV)\n",
    "        inpainted_frame = np.array(inpainted_result)\n",
    "        # Convert RGB to BGR if needed\n",
    "        if len(inpainted_frame.shape) == 3 and inpainted_frame.shape[2] == 3:\n",
    "            inpainted_frame = cv2.cvtColor(inpainted_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Write inpainted frame\n",
    "    out_inpainted.write(inpainted_frame)\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % 10 == 0:  # Print progress every 10 frames\n",
    "        print(f\"Processed {frame_count} frames...\")\n",
    "\n",
    "# Release resources\n",
    "out_original.release()\n",
    "out_inpainted.release()\n",
    "\n",
    "print(f\"Processing complete! Processed {frame_count} frames from raw server stream.\")\n",
    "print(\"Videos saved: ./Original_Webcam.avi and ./SegYolov8_InptSimLama.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both video files opened successfully.\n",
      "Creating side-by-side video...\n",
      "Side-by-side video saved to ./output/side_by_side_output_4.avi\n"
     ]
    }
   ],
   "source": [
    "# Create side-by-side comparison video\n",
    "cap_original = cv2.VideoCapture('./Original_Webcam.avi')\n",
    "cap_inpainted = cv2.VideoCapture('./SegYolov8_InptSimLama.avi')\n",
    "\n",
    "if not cap_original.isOpened():\n",
    "    print(\"Error: Could not open original video file ./Original_Webcam.avi\")\n",
    "    exit()\n",
    "\n",
    "if not cap_inpainted.isOpened():\n",
    "    print(\"Error: Could not open inpainted video file ./SegYolov8_InptSimLama.avi\")\n",
    "    exit()\n",
    "\n",
    "print(\"Both video files opened successfully.\")\n",
    "# Get video properties\n",
    "frame_width = int(cap_original.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap_original.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap_original.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "output_dir = './output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Find the next incrementing number\n",
    "existing_files = [f for f in os.listdir(output_dir) if f.startswith('side_by_side_output_') and f.endswith('.avi')]\n",
    "numbers = []\n",
    "for f in existing_files:\n",
    "    parts = f.split('_')\n",
    "    if len(parts) >= 4 and parts[-1].endswith('.avi'):\n",
    "        num_str = parts[-1].replace('.avi', '')\n",
    "        if num_str.isdigit():\n",
    "            numbers.append(int(num_str))\n",
    "next_num = max(numbers) + 1 if numbers else 1\n",
    "\n",
    "# Define output video path and initialize VideoWriter\n",
    "output_comparison_path = os.path.join(output_dir, f'side_by_side_output_{next_num}.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out_comparison = cv2.VideoWriter(output_comparison_path, fourcc, fps, (frame_width * 2, frame_height))\n",
    "\n",
    "print(\"Creating side-by-side video...\")\n",
    "\n",
    "# Loop through frames and combine\n",
    "while cap_original.isOpened() and cap_inpainted.isOpened():\n",
    "    ret_original, frame_original = cap_original.read()\n",
    "    ret_inpainted, frame_inpainted = cap_inpainted.read()\n",
    "\n",
    "    if not ret_original or not ret_inpainted:\n",
    "        break\n",
    "\n",
    "    # Concatenate frames horizontally\n",
    "    combined_frame = np.concatenate((frame_original, frame_inpainted), axis=1)\n",
    "\n",
    "    # Write the combined frame to the output video\n",
    "    out_comparison.write(combined_frame)\n",
    "\n",
    "# Release resources\n",
    "cap_original.release()\n",
    "cap_inpainted.release()\n",
    "out_comparison.release()\n",
    "\n",
    "print(f\"Side-by-side video saved to {output_comparison_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "https://github.com/kchen2010/MVP-Boeing-Scholars/blob/main/Matt_MVp.ipynb",
     "timestamp": 1761186044334
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
