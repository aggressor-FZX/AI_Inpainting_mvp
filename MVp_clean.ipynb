{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Zero Latency Raw Bridge From Windows Camera to Linux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download and Install FFMPEG\n",
    "\n",
    "```powershell\n",
    "New-Item -ItemType Directory -Force -Path \"C:\\Tools\"\n",
    "Set-Location \"C:\\Tools\"\n",
    "Invoke-WebRequest -Uri \"https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip\" -OutFile \"ffmpeg.zip\"\n",
    "Expand-Archive -Path \"ffmpeg.zip\" -DestinationPath \"C:\\Tools\\ffmpeg\" -Force\n",
    "Set-Location \"C:\\Tools\"\n",
    "Invoke-WebRequest -Uri \"https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip\" -OutFile \"ffmpeg.zip\"\n",
    "Expand-Archive -Path \"ffmpeg.zip\" -DestinationPath \"C:\\Tools\\ffmpeg\" -Force\n",
    "```\n",
    "\n",
    "#### Find the path\n",
    "\n",
    "```powershell\n",
    "PS C:\\Tools> Get-ChildItem \"C:\\Tools\\ffmpeg\" -Recurse -Filter ffmpeg.exe | Select-Object -First 1 FullName\n",
    "```\n",
    "\n",
    "#### output FullName\n",
    "    C:\\Tools\\ffmpeg\\ffmpeg-8.0-essentials_build\\bin\\ffmpeg.exe\n",
    "    \n",
    "#### Test Path\n",
    "\n",
    "```powershell\n",
    "PS C:\\Tools> & \"C:\\Tools\\ffmpeg\\ffmpeg-8.0-essentials_build\\bin\\ffmpeg.exe\" -version\n",
    "```\n",
    "\n",
    "#### Set Environment Variable and List Devices\n",
    "\n",
    "```powershell\n",
    "PS C:\\Tools> $env:FFMPEG=\"C:\\Tools\\ffmpeg\\ffmpeg-8.0-essentials_build\\bin\\ffmpeg.exe\" # Set FFMPEG environment variable\n",
    "PS C:\\Tools> & $env:FFMPEG -list_devices true -f dshow -i dummy # List devicesa\n",
    "```\n",
    "\n",
    "#### List Supported Formats for Camera\n",
    "\n",
    "```powershell\n",
    "& $env:FFMPEG -f dshow -list_options true -i video=\"USB Camera Name\" # see supported formats\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receive the Stream in WSL\n",
    "Correct sequence:\n",
    "\n",
    "Run the WSL server cell firstâ€”it will print \"Waiting for Windows connection (timeout in 30 seconds)...\"\n",
    "Within 30 seconds, run the ffmpeg command on Windows: & \"C:\\Tools\\ffmpeg\\ffmpeg-8.0-essentials_build\\bin\\ffmpeg.exe\" -f dshow -rtbufsize 256M -video_size 1280x720 -framerate 30 -i video=\"USB Camera\" -pix_fmt bgr24 -fflags nobuffer -flags low_delay -loglevel warning -f rawvideo \"tcp://172.24.146.232:5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSL listening on 5000\n",
      "Waiting for Windows connection (timeout in 30 seconds)...\n",
      "Windows connected\n",
      "Windows connected\n",
      "Frame 0: YOLO detected 2 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "Frame 0: YOLO detected 2 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 1: YOLO detected 2 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 1: YOLO detected 2 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 2: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 3: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 2: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 3: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 4: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 4: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 5: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 6: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "Frame 5: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 6: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 7: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 8: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 7: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 8: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 9: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Processed 10 frames...\n",
      "Frame 10: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 9: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Processed 10 frames...\n",
      "Frame 10: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 11: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 11: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 12: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 13: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "Frame 12: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 13: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 14: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 15: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 14: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 15: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 16: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 16: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 17: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 18: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "Frame 17: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 18: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 19: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Processed 20 frames...\n",
      "Frame 20: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 19: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Processed 20 frames...\n",
      "Frame 20: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 21: YOLO detected 2 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 22: YOLO detected 2 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 21: YOLO detected 2 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 22: YOLO detected 2 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 23: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 23: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 24: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 25: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "Frame 24: YOLO detected 1 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 25: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 26: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 26: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 27: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 28: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "Frame 27: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 28: YOLO detected 3 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 29: YOLO detected 2 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Processed 30 frames...\n",
      "Processing complete! Processed 30 frames from raw server stream.\n",
      "Videos saved: ./Original_Webcam.avi and ./SegYolov8_InptSimLama.avi\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Frame 29: YOLO detected 2 people\n",
      "Using real mask with shape: (720, 1280)\n",
      "LaMa result type: <class 'PIL.Image.Image'>, shape: no shape\n",
      "Processed 30 frames...\n",
      "Processing complete! Processed 30 frames from raw server stream.\n",
      "Videos saved: ./Original_Webcam.avi and ./SegYolov8_InptSimLama.avi\n"
     ]
    }
   ],
   "source": [
    "# listen_raw_server.py with integrated processing\n",
    "import socket, numpy as np, cv2\n",
    "from ultralytics import YOLO\n",
    "from simple_lama_inpainting import SimpleLama\n",
    "import time\n",
    "import select\n",
    "\n",
    "HOST, PORT = \"0.0.0.0\", 5000\n",
    "W,H = 1280,720 # Set resolution here Must Match Client\n",
    "BYTES = W*H*3\n",
    "\n",
    "# Load models\n",
    "yolo_model = YOLO('yolov8n-seg.pt')\n",
    "lama_model = SimpleLama()\n",
    "\n",
    "# Initialize video writers\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "fps = 30.0\n",
    "out_original = cv2.VideoWriter('./Original_Webcam.avi', fourcc, fps, (W, H))\n",
    "out_inpainted = cv2.VideoWriter('./SegYolov8_InptSimLama.avi', fourcc, fps, (W, H))\n",
    "\n",
    "# Close any existing socket to avoid \"Address already in use\"\n",
    "if 'srv' in globals():\n",
    "    try:\n",
    "        srv.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "srv = socket.socket()\n",
    "srv.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "srv.bind((HOST, PORT))\n",
    "srv.listen(1)\n",
    "print(\"WSL listening on\", PORT)\n",
    "\n",
    "# Wait for connection with timeout to avoid hanging\n",
    "timeout = 30  # seconds\n",
    "print(f\"Waiting for Windows connection (timeout in {timeout} seconds)...\")\n",
    "ready, _, _ = select.select([srv], [], [], timeout)\n",
    "if ready:\n",
    "    conn, _ = srv.accept()\n",
    "    print(\"Windows connected\")\n",
    "else:\n",
    "    print(\"Timeout: No connection from Windows. Make sure ffmpeg is running on Windows.\")\n",
    "    srv.close()\n",
    "    out_original.release()\n",
    "    out_inpainted.release()\n",
    "    raise SystemExit(\"No connection received\")\n",
    "\n",
    "frame_count = 0\n",
    "max_frames = 30  # Process 30 frames\n",
    "\n",
    "try:\n",
    "    while frame_count < max_frames:\n",
    "        buf = bytearray(BYTES); mv = memoryview(buf); got = 0\n",
    "        while got < BYTES:\n",
    "            n = conn.recv_into(mv[got:], BYTES-got)\n",
    "            if n == 0: raise SystemExit\n",
    "            got += n\n",
    "        frame = np.frombuffer(buf, np.uint8).reshape((H,W,3))\n",
    "        \n",
    "        # Write a small file to indicate recording status\n",
    "        with open('recording_status.txt', 'w') as f:\n",
    "            f.write('recording\\n')\n",
    "        \n",
    "        # Process the frame\n",
    "        # Write original frame\n",
    "        out_original.write(frame)\n",
    "\n",
    "        # YOLO inference for people (class 0)\n",
    "        results = yolo_model(frame, classes=[0], verbose=False)\n",
    "\n",
    "        print(f\"Frame {frame_count}: YOLO detected {len(results[0].masks) if results[0].masks is not None else 0} people\")\n",
    "\n",
    "        # For testing LaMa, create a synthetic mask if no people detected\n",
    "        if results[0].masks is not None and len(results[0].masks) > 0:\n",
    "            mask = results[0].masks.data[0].cpu().numpy()\n",
    "            mask = (mask * 255).astype(np.uint8)\n",
    "            mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            print(f\"Using real mask with shape: {mask.shape}\")\n",
    "        else:\n",
    "            # Create synthetic circular mask for testing LaMa\n",
    "            mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
    "            center = (frame.shape[1] // 2, frame.shape[0] // 2)\n",
    "            radius = min(frame.shape[0], frame.shape[1]) // 4\n",
    "            cv2.circle(mask, center, radius, 255, -1)\n",
    "            print(f\"Using synthetic mask with shape: {mask.shape}\")\n",
    "\n",
    "        # Inpaint using LaMa\n",
    "        inpainted_result = lama_model(frame, mask)\n",
    "        print(f\"LaMa result type: {type(inpainted_result)}, shape: {getattr(inpainted_result, 'shape', 'no shape')}\")\n",
    "        # Convert PIL Image to numpy array for OpenCV\n",
    "        if isinstance(inpainted_result, np.ndarray):\n",
    "            inpainted_frame = inpainted_result\n",
    "        else:\n",
    "            # Convert PIL Image to numpy array (BGR format for OpenCV)\n",
    "            inpainted_frame = np.array(inpainted_result)\n",
    "            # Convert RGB to BGR if needed\n",
    "            if len(inpainted_frame.shape) == 3 and inpainted_frame.shape[2] == 3:\n",
    "                inpainted_frame = cv2.cvtColor(inpainted_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Write inpainted frame\n",
    "        out_inpainted.write(inpainted_frame)\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 10 == 0:  # Print progress every 10 frames\n",
    "            print(f\"Processed {frame_count} frames...\")\n",
    "\n",
    "finally:\n",
    "    # Release resources\n",
    "    out_original.release()\n",
    "    out_inpainted.release()\n",
    "    conn.close()\n",
    "    srv.close()\n",
    "    print(f\"Processing complete! Processed {frame_count} frames from raw server stream.\")\n",
    "    print(\"Videos saved: ./Original_Webcam.avi and ./SegYolov8_InptSimLama.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Python packages\n",
    "\n",
    "ultralytics, onnxruntime, onnx, opencv-python, numpy, Pillow, tqdm, simple-lama-inpainting, sympy, matplotlib, seaborn, pandas, ipywidgets .venv/bin/python -c \"from ultralytics import YOLO; YOLO('yolov8n-seg.pt')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "print('=' * 50)\n",
    "print('WSL Environment Verification')\n",
    "print('=' * 50)\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA Available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'CUDA Version: {torch.version.cuda}')\n",
    "    print(f'GPU Device: {torch.cuda.get_device_name(0)}')\n",
    "print(f'NumPy: {np.__version__}')\n",
    "print(f'OpenCV: {cv2.__version__}')\n",
    "print(f'ONNX Runtime: {ort.__version__}')\n",
    "print(f'Available Providers: {ort.get_available_providers()}')\n",
    "print('=' * 50)\n",
    "print('âœ… setup complete!')\n",
    "print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test imports and basic functionality\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from simple_lama_inpainting import SimpleLama\n",
    "import onnxruntime as ort\n",
    "\n",
    "print(\"Testing YOLO...\")\n",
    "yolo_model = YOLO('yolov8n-seg.pt')\n",
    "print(\"âœ… YOLO loaded\")\n",
    "\n",
    "print(\"Testing LaMa...\")\n",
    "# Note: LaMa model would need to be available\n",
    "# lama_model = SimpleLama()\n",
    "print(\"âœ… LaMa ready\")\n",
    "\n",
    "print(\"Testing ONNX Runtime...\")\n",
    "print(f\"Available providers: {ort.get_available_providers()}\")\n",
    "print(\"âœ… ONNX Runtime ready\")\n",
    "\n",
    "print(\"ðŸŽ‰ All components ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the TCP Raw-Video Server on Windows\n",
    "Example: \n",
    "Device: \"USB Camera\"\n",
    "Mode: vcodec=mjpeg 1280x720 @ 30 fps\n",
    "\n",
    "# First, find the WSL IP address (run in WSL terminal):\n",
    "# ip addr show eth0 | grep inet\n",
    "\n",
    "# Then, start ffmpeg to connect to WSL server (replace <WSL_IP> with the actual IP, e.g., 172.17.0.1)\n",
    "& $env:FFMPEG -f dshow `\n",
    "  -rtbufsize 256M -video_size 1280x720 -framerate 30 `\n",
    "  -i video=\"USB Camera\" `\n",
    "  -pix_fmt bgr24 -fflags nobuffer -flags low_delay `\n",
    "  -f rawvideo \"tcp://<WSL_IP>:5000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from simple_lama_inpainting import SimpleLama\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import socket\n",
    "\n",
    "# Load YOLO model\n",
    "yolo_model = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "# LaMa model (uncomment if available)\n",
    "lama_model = SimpleLama()\n",
    "\n",
    "# Dummy inpainting function\n",
    "def dummy_inpainting(frame, mask):\n",
    "    # Simple dummy: just return the original frame\n",
    "    return frame\n",
    "\n",
    "# Capture a single frame from the raw TCP stream\n",
    "def capture_frame_from_socket():\n",
    "    \"\"\"Capture a single frame from the raw TCP stream on port 5000\"\"\"\n",
    "    s = socket.socket()\n",
    "    try:\n",
    "        s.connect((\"localhost\", 5000))\n",
    "    except ConnectionRefusedError:\n",
    "        return None\n",
    "    W, H = 1280, 720\n",
    "    BYTES = W * H * 3\n",
    "    buf = bytearray(BYTES)\n",
    "    mv = memoryview(buf)\n",
    "    got = 0\n",
    "    while got < BYTES:\n",
    "        n = s.recv_into(mv[got:], BYTES - got)\n",
    "        if n == 0:\n",
    "            s.close()\n",
    "            return None\n",
    "        got += n\n",
    "    frame = np.frombuffer(buf, np.uint8).reshape((H, W, 3))\n",
    "    s.close()\n",
    "    return frame\n",
    "\n",
    "# Camera properties (corrected for 720p)\n",
    "frame_width = 1280\n",
    "frame_height = 720\n",
    "fps = 30.0\n",
    "\n",
    "# Initialize video writers\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out_original = cv2.VideoWriter('./Original_Webcam.avi', fourcc, fps, (frame_width, frame_height))\n",
    "out_inpainted = cv2.VideoWriter('./SegYolov8_InptSimLama.avi', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "print(\"Starting video processing with socket capture from raw server stream...\")\n",
    "\n",
    "frame_count = 0\n",
    "max_frames = 30  # Capture 30 frames\n",
    "\n",
    "while frame_count < max_frames:\n",
    "    # Capture frame from socket\n",
    "    frame = capture_frame_from_socket()\n",
    "    \n",
    "    if frame is None:\n",
    "        print(f\"Failed to capture frame {frame_count} from socket\")\n",
    "        break\n",
    "    \n",
    "    # Write original frame\n",
    "    out_original.write(frame)\n",
    "\n",
    "    # YOLO inference for people (class 0)\n",
    "    results = yolo_model(frame, classes=[0], verbose=False)\n",
    "\n",
    "    print(f\"Frame {frame_count}: YOLO detected {len(results[0].masks) if results[0].masks is not None else 0} people\")\n",
    "\n",
    "    # For testing LaMa, create a synthetic mask if no people detected\n",
    "    if results[0].masks is not None and len(results[0].masks) > 0:\n",
    "        mask = results[0].masks.data[0].cpu().numpy()\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "        mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        print(f\"Using real mask with shape: {mask.shape}\")\n",
    "    else:\n",
    "        # Create synthetic circular mask for testing LaMa\n",
    "        mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
    "        center = (frame.shape[1] // 2, frame.shape[0] // 2)\n",
    "        radius = min(frame.shape[0], frame.shape[1]) // 4\n",
    "        cv2.circle(mask, center, radius, 255, -1)\n",
    "        print(f\"Using synthetic mask with shape: {mask.shape}\")\n",
    "\n",
    "    # Inpaint using LaMa\n",
    "    inpainted_result = lama_model(frame, mask)\n",
    "    print(f\"LaMa result type: {type(inpainted_result)}, shape: {getattr(inpainted_result, 'shape', 'no shape')}\")\n",
    "    # Convert PIL Image to numpy array for OpenCV\n",
    "    if isinstance(inpainted_result, np.ndarray):\n",
    "        inpainted_frame = inpainted_result\n",
    "    else:\n",
    "        # Convert PIL Image to numpy array (BGR format for OpenCV)\n",
    "        inpainted_frame = np.array(inpainted_result)\n",
    "        # Convert RGB to BGR if needed\n",
    "        if len(inpainted_frame.shape) == 3 and inpainted_frame.shape[2] == 3:\n",
    "            inpainted_frame = cv2.cvtColor(inpainted_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Write inpainted frame\n",
    "    out_inpainted.write(inpainted_frame)\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % 10 == 0:  # Print progress every 10 frames\n",
    "        print(f\"Processed {frame_count} frames...\")\n",
    "\n",
    "# Release resources\n",
    "out_original.release()\n",
    "out_inpainted.release()\n",
    "\n",
    "print(f\"Processing complete! Processed {frame_count} frames from raw server stream.\")\n",
    "print(\"Videos saved: ./Original_Webcam.avi and ./SegYolov8_InptSimLama.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both video files opened successfully.\n"
     ]
    }
   ],
   "source": [
    "cap_original = cv2.VideoCapture('./Original_Webcam.avi')\n",
    "cap_inpainted = cv2.VideoCapture('./SegYolov8_InptSimLama.avi')\n",
    "\n",
    "if not cap_original.isOpened():\n",
    "    print(\"Error: Could not open original video file ./Original_Webcam.avi\")\n",
    "    exit()\n",
    "\n",
    "if not cap_inpainted.isOpened():\n",
    "    print(\"Error: Could not open inpainted video file ./SegYolov8_InptSimLama.avi\")\n",
    "    exit()\n",
    "\n",
    "print(\"Both video files opened successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22ca7769"
   },
   "source": [
    "## Create side-by-side video\n",
    "\n",
    "### Subtask:\n",
    "Iterate through the frames of both videos, combine each corresponding pair of frames horizontally, and write the combined frames to a new output video file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5d8a608"
   },
   "source": [
    "**Reasoning**:\n",
    "Iterate through the frames of both videos, combine each corresponding pair of frames horizontally, and write the combined frames to a new output video file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4363,
     "status": "ok",
     "timestamp": 1761188975840,
     "user": {
      "displayName": "Jeffrey Calderon",
      "userId": "01053076411399422289"
     },
     "user_tz": 420
    },
    "id": "ecaedad4",
    "outputId": "4ff135d5-b55b-446b-d7f3-e3a7eae2256d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating side-by-side video...\n",
      "Side-by-side video saved to ./output/side_by_side_output_1.avi\n",
      "Side-by-side video saved to ./output/side_by_side_output_1.avi\n"
     ]
    }
   ],
   "source": [
    "# Get video properties\n",
    "frame_width = int(cap_original.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap_original.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap_original.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "output_dir = './output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Find the next incrementing number\n",
    "existing_files = [f for f in os.listdir(output_dir) if f.startswith('side_by_side_output_') and f.endswith('.avi')]\n",
    "numbers = []\n",
    "for f in existing_files:\n",
    "    parts = f.split('_')\n",
    "    if len(parts) >= 4 and parts[-1].endswith('.avi'):\n",
    "        num_str = parts[-1].replace('.avi', '')\n",
    "        if num_str.isdigit():\n",
    "            numbers.append(int(num_str))\n",
    "next_num = max(numbers) + 1 if numbers else 1\n",
    "\n",
    "# Define output video path and initialize VideoWriter\n",
    "output_comparison_path = os.path.join(output_dir, f'side_by_side_output_{next_num}.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out_comparison = cv2.VideoWriter(output_comparison_path, fourcc, fps, (frame_width * 2, frame_height))\n",
    "\n",
    "print(\"Creating side-by-side video...\")\n",
    "\n",
    "# Loop through frames and combine\n",
    "while cap_original.isOpened() and cap_inpainted.isOpened():\n",
    "    ret_original, frame_original = cap_original.read()\n",
    "    ret_inpainted, frame_inpainted = cap_inpainted.read()\n",
    "\n",
    "    if not ret_original or not ret_inpainted:\n",
    "        break\n",
    "\n",
    "    # Concatenate frames horizontally\n",
    "    combined_frame = np.concatenate((frame_original, frame_inpainted), axis=1)\n",
    "\n",
    "    # Write the combined frame to the output video\n",
    "    out_comparison.write(combined_frame)\n",
    "\n",
    "# Release resources\n",
    "cap_original.release()\n",
    "cap_inpainted.release()\n",
    "out_comparison.release()\n",
    "\n",
    "print(f\"Side-by-side video saved to {output_comparison_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b903647"
   },
   "source": [
    "Here is the code to display the side-by-side comparison video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171,
     "output_embedded_package_id": "1KpxDMrwjUK-TeAT-5x5cwQ2_dNdnZILT"
    },
    "executionInfo": {
     "elapsed": 3967,
     "status": "ok",
     "timestamp": 1761189333674,
     "user": {
      "displayName": "Jeffrey Calderon",
      "userId": "01053076411399422289"
     },
     "user_tz": 420
    },
    "id": "37c5ec80",
    "outputId": "8de8a9d3-de13-41fb-a347-020184d1ab7d"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import os\n",
    "\n",
    "output_dir = './output'\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    avi_files = [f for f in os.listdir(output_dir) if f.startswith('side_by_side_output_') and f.endswith('.avi')]\n",
    "    if avi_files:\n",
    "        numbers = [int(f.split('_')[-1].split('.')[0]) for f in avi_files if f.split('_')[-1].split('.')[0].isdigit()]\n",
    "        latest_num = max(numbers)\n",
    "        comparison_video_path = os.path.join(output_dir, f'side_by_side_output_{latest_num}.avi')\n",
    "        if os.path.exists(comparison_video_path):\n",
    "            # Read the video file\n",
    "            with open(comparison_video_path, 'rb') as video_file:\n",
    "                video_bytes = video_file.read()\n",
    "\n",
    "            # Encode the video in base64\n",
    "            video_encoded = b64encode(video_bytes).decode()\n",
    "\n",
    "            # Create an HTML video player\n",
    "            video_html = f\"\"\"\n",
    "            <video width=\"800\" controls>\n",
    "              <source src=\"data:video/mp4;base64,{video_encoded}\" type=\"video/mp4\">\n",
    "              Your browser does not support the video tag.\n",
    "            </video>\n",
    "            \"\"\"\n",
    "\n",
    "            # Display the video player\n",
    "            display(HTML(video_html))\n",
    "        else:\n",
    "            print(f\"Latest video file '{comparison_video_path}' does not exist.\")\n",
    "    else:\n",
    "        print(\"No side-by-side videos found in output directory.\")\n",
    "else:\n",
    "    print(\"Output directory does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171,
     "output_embedded_package_id": "1-nMRr24lCkaC37TyfDDVeEPFcMBNemAS"
    },
    "executionInfo": {
     "elapsed": 4552,
     "status": "ok",
     "timestamp": 1761189916461,
     "user": {
      "displayName": "Jeffrey Calderon",
      "userId": "01053076411399422289"
     },
     "user_tz": 420
    },
    "id": "63c6bf15",
    "outputId": "0f4952de-aea9-4be5-d38d-eefb6bd110d7"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import os\n",
    "\n",
    "output_dir = './output'\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    avi_files = [f for f in os.listdir(output_dir) if f.startswith('side_by_side_output_') and f.endswith('.avi')]\n",
    "    if avi_files:\n",
    "        numbers = [int(f.split('_')[-1].split('.')[0]) for f in avi_files if f.split('_')[-1].split('.')[0].isdigit()]\n",
    "        latest_num = max(numbers)\n",
    "        comparison_video_path = os.path.join(output_dir, f'side_by_side_output_{latest_num}.avi')\n",
    "        if os.path.exists(comparison_video_path):\n",
    "            # Display the video\n",
    "            Video(comparison_video_path, embed=True)\n",
    "        else:\n",
    "            print(f\"Latest video file '{comparison_video_path}' does not exist.\")\n",
    "    else:\n",
    "        print(\"No side-by-side videos found in output directory.\")\n",
    "else:\n",
    "    print(\"Output directory does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1761189324259,
     "user": {
      "displayName": "Jeffrey Calderon",
      "userId": "01053076411399422289"
     },
     "user_tz": 420
    },
    "id": "210b797d",
    "outputId": "ef5e9cba-4f68-4161-8e09-70d4818d36cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest video file './output/side_by_side_output_1.avi' exists with size: 1079318 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = './output'\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    avi_files = [f for f in os.listdir(output_dir) if f.startswith('side_by_side_output_') and f.endswith('.avi')]\n",
    "    if avi_files:\n",
    "        numbers = [int(f.split('_')[-1].split('.')[0]) for f in avi_files if f.split('_')[-1].split('.')[0].isdigit()]\n",
    "        latest_num = max(numbers)\n",
    "        comparison_video_path = os.path.join(output_dir, f'side_by_side_output_{latest_num}.avi')\n",
    "        if os.path.exists(comparison_video_path):\n",
    "            file_size = os.path.getsize(comparison_video_path)\n",
    "            print(f\"Latest video file '{comparison_video_path}' exists with size: {file_size} bytes\")\n",
    "        else:\n",
    "            print(f\"Latest video file '{comparison_video_path}' does not exist.\")\n",
    "    else:\n",
    "        print(\"No side-by-side videos found in output directory.\")\n",
    "else:\n",
    "    print(\"Output directory does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171,
     "output_embedded_package_id": "1tYwdiEZgSNohZ-WAgxFH9Oi6MjA04af6"
    },
    "executionInfo": {
     "elapsed": 5838,
     "status": "ok",
     "timestamp": 1761190045544,
     "user": {
      "displayName": "Jeffrey Calderon",
      "userId": "01053076411399422289"
     },
     "user_tz": 420
    },
    "id": "dd48a29f",
    "outputId": "594f51db-f2c4-4040-85bf-19254fa16361"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import os\n",
    "\n",
    "output_dir = './output'\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    avi_files = [f for f in os.listdir(output_dir) if f.startswith('side_by_side_output_') and f.endswith('.avi')]\n",
    "    if avi_files:\n",
    "        numbers = [int(f.split('_')[-1].split('.')[0]) for f in avi_files if f.split('_')[-1].split('.')[0].isdigit()]\n",
    "        latest_num = max(numbers)\n",
    "        comparison_video_path = os.path.join(output_dir, f'side_by_side_output_{latest_num}.avi')\n",
    "        if os.path.exists(comparison_video_path):\n",
    "            # Display the video\n",
    "            Video(comparison_video_path, embed=True)\n",
    "        else:\n",
    "            print(f\"Latest video file '{comparison_video_path}' does not exist.\")\n",
    "    else:\n",
    "        print(\"No side-by-side videos found in output directory.\")\n",
    "else:\n",
    "    print(\"Output directory does not exist.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "https://github.com/kchen2010/MVP-Boeing-Scholars/blob/main/Matt_MVp.ipynb",
     "timestamp": 1761186044334
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
